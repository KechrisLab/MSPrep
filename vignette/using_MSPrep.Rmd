---
title: "Using MSPrep"
author: 
    - name: Matt Mulvahill
      email: matt.mulvahill@gmail.com
      affiliation: Charter Communications
    - name: Grant Hughes
      email: dydxhughes@gmail.com
    - name: Sean Jacobson
      email: jacobsons@njhealth.org
      affiliation: National Jewish Hospital
    - name: Harrison Pielke-Lombardo
      email: harrison.pielke-lombardo@ucdenver.edu
      affiliation: University of Colorado Anschutz Medical Campus
    - name: Katerina Kechris
      email: katerina.kechris@ucdenver.edu
      affiliation: University of Colorado Anschutz Medical Campus
package: MSPrep
output: 
  BiocStyle::html_document:
    highlight: "tango"
    code_folding: show
    toc: true
    toc_float: 
      collapsed: false
vignette: |
  %\VignetteIndexEntry{Using MSPrep}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}  
---

```{r, include=FALSE, echo=FALSE}
# date: "`r doc_date()`"
# "`r pkg_ver('BiocStyle')`"
# <style>
#     pre {
#     white-space: pre !important;
#     overflow-y: scroll !important;
#     height: 50vh !important;
#     }
# </style>
```

# Introduction

MSPrep provides five key functions for preparing metabolomics data for analysis. This vignette will provide
- an explanation of each functions
- suggestions for how to select parameters
- an explanation of how to use the final outputted data
- code to perform all of the steps in a pipeline

# Loading libraries

```{r}
library(MSPrep)
library(tidyverse)
```

# Getting our columns in order

We first need to format the data. The following format is expected for most types of data generated from mass spectrometry.

The first two columns are for the mass-to-charge ratio and the retention-time, in this order. They can have any name you would like (e.g., "mz" and "rt").

The next columns are for the other sample variables. These columns should have names that contain information about their contents which will be used later in the pipeline (e.g., SampleID). There are three pieces of information which need to be present at the end of each column name, separated by a consistent separator. These are the spike, batch, and replicate ID.

As an example see the provided dataset, msquant.

```{r}
data("msquant")
strsplit(colnames(msquant)[3], "_")
```

The third column name is `colnames(msquant)[3]`. The first part "Neutral_Operator_Dif_Pos_" will not be used, so we will assign it to col_extra_txt. The next value, "1x", is the spike-in value. The following value, "O1", is the batch. The remaining values, "A" and "01", are the replicate and subject IDs.

Identifiers in the datasets
- LCMS_Run_ID = operator/replicate (A-C), subject (01-03), concentration  (1x,2x,4x)
- SubjectID   = subject (01-03), concentration  (1x,2x,4x)

With our data in this format, we can start the pipeline.

# Tidying the data

The first step is to extract the information from the column names discussed above, and get it into a tidy data frame. We can do this with the ms_tidy function.

```{r}
tidied_data = ms_tidy(msquant, mz = "mz", rt = "rt", col_extra_txt = "Neutral_Operator_Dif_Pos_", separator = "_", col_names = c("spike", "batch", "replicate", "subject_id"))
```

Note, the names chosen for col_names are arbitratry, but we will use them later on.

# Preparing the data

This step summarizes the technical replicates, using the following procedure for each compound in each batch.

1. If there are less than a minimum proportion of the values found among the replicates (usually one or zero), leave the value empty. Otherwise proceed.
1. Calculate the coefficient of variation between the replicates using $c_v = \frac{\sigma}{\mu}$, where $\mu$ is the mean and $\sigma$ is the standard deviation.
2. For three replicates, if the coefficient of variation is above a specified level, use the median value for the compound, to correct for the large dispersion.
3. Otherwise, use the mean value of the replicates for the compound.

```{r}
summarized_data = ms_prepare(tidied_data, mz = "mz", rt = "rt", replicate = "replicate", batch = "batch", groupingvars = "spike", subject_id = "subject_id", cvmax = 0.50, min_proportion_present = 1/3, missing_val = 1)
```

# Filtering missing compounds

This step is straightforward but very important. Simply supply a percentage of the number of samples for which a compound needs to have data present in order to be retained in the next steps.

```{r}
filtered_data = ms_filter(summarized_data, filter_percent=0.8)
```

# Imputing missing values

Next, depending on the downstream analysis, you may need to impute missing data. We provide three methods:

1. half-min (half the minimum value)
2. bpca (Bayesian PCA), 
3. knn (k-nearest neighbors)

Half-min is the fastest, but may introduce bias. KNN typically takes the longest. If you choose to use KNN, you can provide a value for k.

```{r}
imputed_data = ms_impute(filtered_data, method ="knn", k = 5)
```

# Normalizing the data

In order to make comparisons between sample, the data need to be normalized. This step performs one of six normalization strategies. 

# ComBat ()
# quantile + ComBat()
# median + ComBat()
# CRMN ()
# RUV ()
# SVA ()

For experiments which have control compounds, a list of the column numbers containing them should be provided in the controls variable. Otherwise, simply leave the controls parameter blank or NULL. 

```{r}
normalized_data = ms_normalize(imputed_data, method ="CRMN", controls = NULL,  n_comp = 2, n_control = 10)
```

# Final output

# Performing all steps as a pipline

Often, you will want to perform the whole pipeline. This can easily be done in a single statement using the %>% operator from the magrittr package. This threads the result of each function into the first position of the next.

```{r}
dat <-
  msquant %>%
  ms_tidy %>%
  ms_prepare(replicate = "replicate", batch = "batch", groupingvars = "spike") %>%
  ms_filter(0.8) %>%
  ms_impute(method = "halfmin") %>%
  ms_normalize(method = "quantile + ComBat")
```
